# PySpark pandas_udf. Примеры использования.  
Представлены примеры для изучения и использования механизма Apache Spark - Pandas UDF. 

## Overview
**Pandas UDF** (User Defined Function) — механизм Apache Spark, для создания пользовательских функций обработки данных с использованием API библиотеки pandas. Пользовательские функции, выполняются Spark с помощью Arrow для передачи данных и Pandas для работы с данными. Это позволяет выполнять векторизованные операции. Функции определяется с использованием ```@pandas_udf``` в качестве декоратора для преобразования существующих функций pandas в распределенные операции Spark.

✅ **Подходит для:**
- Сложных математических вычислений
- Обработки текста и регулярных выражений
- Статистического анализа по группам
- Применения ML моделей
- Работы с временными рядами
- Когда нужна высокая производительность

❌ **Не подходит для:**
- Простых операций (лучше использовать встроенные функции Spark)
- Операций с малыми данными (иногда происходит значительное замедление)
- Когда достаточно SQL функций (всегда быстрее)
  
### **Типы pandas UDF**
   - *Скалярные* — используются для векторизации скалярных операций. Принимают pandas.Series в качестве аргументов и возвращают другой pandas.Series того же размера.
   - *Групповые* — разбивают DataFrame на группы на основе условий, указанных в операторе groupby, применяют пользовательскую функцию к каждой группе, объединяют и возвращают результаты в новый DataFrame.

| Тип | Скалярные/Групповые | Возвращаемое значение | Трансормация |
|:----|:-----|:------|:--------------|
| **SCALAR** | Скалярные | Series | Поэлементные преобразования (скалярные вычисления) |
| **SCALAR_ITER** | Скалярные | Iterator[Series] | Батчевые преобразования (скалярные вычисления) |
| **GROUPED_MAP** (устар.) | Групповые | DataFrame | Сложная обработка групп. Применение через .applyInPandas |
| **GROUPED_AGG** | Групповые | Scalar | Агрегация групп.  Применение через @pandas_udf(type). Иттеративная обработка |
| - | Скалярные | Iterator | Обработка партиций Spark  Применение через mapInPandas |
| - | Скалярные | Scalar | Обработка двух групп  Spark  Применение через  .cogroup().applyInPandas() |

## Essence
```python
'''Вместо обычной (медленной) UDF '''
@udf("double")
def slow_function(value):
    return value ** 2  # Обрабатывает по одному элементу

'''Используется (быстрая) Pandas UDF '''
@pandas_udf("double")
def fast_function(series: pd.Series) -> pd.Series:
    return series ** 2  # Обрабатывает целые блоки данных
```

## Notebooks
|Notebook|Описание|
|:-|:-|
|[pyspark-pandas-udf](pyspark_pandas_udf_scalar.ipynb)|Пример использования скалярных pandas UDF |
|Apache Spark|Пример использования групповых pandas UDF|

## Requirements
|Инструмент|Версия|Комментарий|Ресурс|
|:-|:-|:-|:-|
|Python3|Python 3.13.7|Версия уже установлена в Ubuntu, устанавливать не требуется, просто проверить|https://www.python.org/|
|Apache Spark|3.5.7|Фреймворк с открытым исходным кодом для реализации распределённой обработки данных, входящий в экосистему проектов Hadoop. |https://spark.apache.org/|
|Jupyter Notebook|7.4.3|Интерактивный блокнот для выполнения кода на различных языках программирования.|https://jupyter.org/|



